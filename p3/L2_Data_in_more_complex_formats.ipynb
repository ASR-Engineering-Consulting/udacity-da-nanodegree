{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2\n",
    "## Data in more complex formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrier list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = \"options.html\"\n",
    "with open(page, \"r\") as html:\n",
    "    soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<option selected=\"selected\" value=\"All\">All U.S. and Foreign Carriers</option>, <option value=\"AllUS\">All U.S. Carriers</option>, <option value=\"AllForeign\">All Foreign Carriers</option>, <option value=\"FL\">AirTran Airways</option>, <option value=\"AS\">Alaska Airlines </option>, <option value=\"AA\">American Airlines </option>, <option value=\"MQ\">American Eagle Airlines </option>, <option value=\"5Y\">Atlas Air </option>, <option value=\"DL\">Delta Air Lines </option>, <option value=\"EV\">ExpressJet Airlines </option>, <option value=\"F9\">Frontier Airlines </option>, <option value=\"HA\">Hawaiian Airlines </option>, <option value=\"B6\">JetBlue Airways</option>, <option value=\"OO\">SkyWest Airlines </option>, <option value=\"WN\">Southwest Airlines </option>, <option value=\"NK\">Spirit Air Lines</option>, <option value=\"US\">US Airways </option>, <option value=\"UA\">United Air Lines </option>, <option value=\"VX\">Virgin America</option>]\n"
     ]
    }
   ],
   "source": [
    "cl = soup.find(id=\"CarrierList\").find_all(\"option\")\n",
    "print(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FL', 'AS', 'AA', 'MQ', '5Y', 'DL', 'EV', 'F9', 'HA', 'B6', 'OO', 'WN', 'NK', 'US', 'UA', 'VX']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for e in cl:\n",
    "    if (e[\"value\"] == \"All\") | (e[\"value\"] == \"AllUS\") | (e[\"value\"] == \"AllForeign\"):\n",
    "        next\n",
    "    else:\n",
    "        result.append(e[\"value\"])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Please note that the function 'make_request' is provided for your reference only.\n",
    "You will not be able to to actually use it from within the Udacity web UI.\n",
    "All your changes should be in the 'extract_carrier' function.\n",
    "Also note that the html file is a stripped down version of what is actually on\n",
    "the website.\n",
    "\n",
    "Your task in this exercise is to get a list of all airlines. Exclude all of the\n",
    "combination values like \"All U.S. Carriers\" from the data that you return.\n",
    "You should return a list of codes for the carriers.\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "html_page = \"options.html\"\n",
    "\n",
    "\n",
    "def extract_carriers(page):\n",
    "    data = []\n",
    "\n",
    "    with open(page, \"r\") as html:\n",
    "        # parse html pasge\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        \n",
    "        # find list of carries in parsed page\n",
    "        carrierlist = soup.find(id=\"CarrierList\").find_all(\"option\")\n",
    "        \n",
    "        # filter combination values and save valid results to list\n",
    "        for e in carrierlist:\n",
    "            if (e[\"value\"] == \"All\") | (e[\"value\"] == \"AllUS\") | (e[\"value\"] == \"AllForeign\"):\n",
    "                next\n",
    "            else:\n",
    "                data.append(e[\"value\"])\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def make_request(data):\n",
    "    eventvalidation = data[\"eventvalidation\"]\n",
    "    viewstate = data[\"viewstate\"]\n",
    "    airport = data[\"airport\"]\n",
    "    carrier = data[\"carrier\"]\n",
    "\n",
    "    r = requests.post(\"http://www.transtats.bts.gov/Data_Elements.aspx?Data=2\",\n",
    "                    data={'AirportList': airport,\n",
    "                          'CarrierList': carrier,\n",
    "                          'Submit': 'Submit',\n",
    "                          \"__EVENTTARGET\": \"\",\n",
    "                          \"__EVENTARGUMENT\": \"\",\n",
    "                          \"__EVENTVALIDATION\": eventvalidation,\n",
    "                          \"__VIEWSTATE\": viewstate\n",
    "                    })\n",
    "\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = extract_carriers(html_page)\n",
    "    assert len(data) == 16\n",
    "    assert \"FL\" in data\n",
    "    assert \"NK\" in data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['ATL', 'BWI', 'BOS', 'CLT', 'MDW', 'ORD', 'DFW', 'DEN', 'DTW', 'FLL', 'IAH', 'LAS', 'LAX', 'ABR', 'ABI']\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Complete the 'extract_airports' function so that it returns a list of airport\n",
    "codes, excluding any combinations like \"All\".\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "html_page = \"options.html\"\n",
    "\n",
    "\n",
    "def extract_airports(page):\n",
    "    data = []\n",
    "    with open(page, \"r\") as html:\n",
    "        # parse html pasge\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        \n",
    "        # find list of airports in parsed page\n",
    "        airportlist = soup.find(id=\"AirportList\").find_all(\"option\")\n",
    "        \n",
    "        # filter combination values and save valid results to list\n",
    "        for e in airportlist:\n",
    "            if (e[\"value\"] == \"All\") | (e[\"value\"] == \"AllMajors\") | (e[\"value\"] == \"AllOthers\"):\n",
    "                next\n",
    "            else:\n",
    "                data.append(e[\"value\"])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = extract_airports(html_page)\n",
    "    assert len(data) == 15\n",
    "    assert \"ATL\" in data\n",
    "    assert \"ABR\" in data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page2 = \"FL-ATL.htm\"\n",
    "with open(page2, \"r\") as html:\n",
    "    soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" cellpadding=\"4\" cellspacing=\"1\" class=\"dataTDRight\" id=\"DataGrid1\" rules=\"all\" style=\"width:750px;\">\n",
      "<tr class=\"libraryTHY2_Center\" style=\"color:White;background-color:#5D95C9;\">\n",
      "<td>Year</td><td>Month</td><td>DOMESTIC</td><td>INTERNATIONAL</td><td>TOTAL</td>\n",
      "</tr><tr class=\"dataTDRight\">\n",
      "<td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">2002</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">10</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">815,489</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">92,565</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">908,054</td>\n",
      "</tr><tr class=\"dataTDRight\" style=\"background-color:#EFEFEF;\">\n",
      "<td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">2002</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">11</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">766,775</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">91,342</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">858,117</td>\n",
      "</tr><tr class=\"dataTDRight\">\n",
      "<td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">2002</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">12</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">782,175</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">96,881</td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\">879,056</td>\n",
      "</tr><tr class=\"dataTDRight\" style=\"background-color:LightYellow;\">\n",
      "<td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\"><b>2002</b></td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\"><b>TOTAL</b></td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\"><b>8,085,083</b></td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\"><b>1,023,994</b></td><td style=\"font-family: Verdana, Geneva, Arial, Helvetica, sans-serif;\"><b>9,109,077</b></td>\n",
      "</tr><tr class=\"dataTDRight\">\n",
      "</tr>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "table = soup.find(\"table\", class_=\"dataTDRight\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': 2002, 'month': 10, 'flights': {'international': 92565, 'domestic': 815489}}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "info = {}\n",
    "result = []\n",
    "header = [\"Year\", \"Month\", \"DOMESTIC\", \"INTERNATIONAL\", \"TOTAL\"]\n",
    "\n",
    "# loop over rows\n",
    "for row in table.find_all(\"tr\"):\n",
    "    \n",
    "    # loop over columns\n",
    "    for col in row.find_all(\"td\"):\n",
    "        \n",
    "        # filter header strings\n",
    "        if col.text in header:\n",
    "            pass\n",
    "        \n",
    "        # add data to result and fix thousand separator\n",
    "        else:\n",
    "            result.append(col.text.replace(\",\", \"\"))\n",
    "            \n",
    "# save result data for each row\n",
    "info[\"year\"] = int(result[0])\n",
    "info[\"month\"] = int(result[1])\n",
    "info[\"flights\"] = {}\n",
    "info[\"flights\"][\"domestic\"] = int(result[2])\n",
    "info[\"flights\"][\"international\"] = int(result[3])\n",
    "    \n",
    "# append temp data to final result\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': 2002, 'month': 10, 'flights': {'international': 92565, 'domestic': 815489}}\n"
     ]
    }
   ],
   "source": [
    "info = {}\n",
    "info[\"year\"] = int(result[0])\n",
    "info[\"month\"] = int(result[1])\n",
    "info[\"flights\"] = {}\n",
    "info[\"flights\"][\"domestic\"] = int(result[2])\n",
    "info[\"flights\"][\"international\"] = int(result[3])\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a simple test...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-5ff9f47b4317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-149-5ff9f47b4317>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running a simple test...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mopen_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-5ff9f47b4317>\u001b[0m in \u001b[0;36mopen_zip\u001b[0;34m(datadir)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0}.zip'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mmyzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stefan/anaconda/lib/python3.4/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0mmodeDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'r'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'r+b'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.zip'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Let's assume that you combined the code from the previous 2 exercises with code\n",
    "from the lesson on how to build requests, and downloaded all the data locally.\n",
    "The files are in a directory \"data\", named after the carrier and airport:\n",
    "\"{}-{}.html\".format(carrier, airport), for example \"FL-ATL.html\".\n",
    "\n",
    "The table with flight info has a table class=\"dataTDRight\". Your task is to\n",
    "extract the flight data from that table as a list of dictionaries, each\n",
    "dictionary containing relevant data from the file and table row. This is an\n",
    "example of the data structure you should return:\n",
    "\n",
    "data = [{\"courier\": \"FL\",\n",
    "         \"airport\": \"ATL\",\n",
    "         \"year\": 2012,\n",
    "         \"month\": 12,\n",
    "         \"flights\": {\"domestic\": 100,\n",
    "                     \"international\": 100}\n",
    "        },\n",
    "         {\"courier\": \"...\"}\n",
    "]\n",
    "\n",
    "Note - year, month, and the flight data should be integers.\n",
    "You should skip the rows that contain the TOTAL data for a year.\n",
    "\n",
    "There are couple of helper functions to deal with the data files.\n",
    "Please do not change them for grading purposes.\n",
    "All your changes should be in the 'process_file' function.\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "#datadir = \"data\"\n",
    "datadir = \"\"\n",
    "\n",
    "def open_zip(datadir):\n",
    "    with ZipFile('{0}.zip'.format(datadir), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def process_all(datadir):\n",
    "    files = os.listdir(datadir)\n",
    "    return files\n",
    "\n",
    "\n",
    "def process_file(f):\n",
    "    \"\"\"\n",
    "    This function extracts data from the file given as the function argument in\n",
    "    a list of dictionaries. This is example of the data structure you should\n",
    "    return:\n",
    "\n",
    "    data = [{\"courier\": \"FL\",\n",
    "             \"airport\": \"ATL\",\n",
    "             \"year\": 2012,\n",
    "             \"month\": 12,\n",
    "             \"flights\": {\"domestic\": 100,\n",
    "                         \"international\": 100}\n",
    "            },\n",
    "            {\"courier\": \"...\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "    Note - year, month, and the flight data should be integers.\n",
    "    You should skip the rows that contain the TOTAL data for a year.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    info = {}\n",
    "    info[\"courier\"], info[\"airport\"] = f[:6].split(\"-\")\n",
    "    # Note: create a new dictionary for each entry in the output data list.\n",
    "    # If you use the info dictionary defined here each element in the list \n",
    "    # will be a reference to the same info dictionary.\n",
    "    with open(\"{}/{}\".format(datadir, f), \"r\") as html:\n",
    "        \n",
    "        # parse html data\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        \n",
    "        # find relevant data\n",
    "        table = soup.find(\"table\", class_=\"dataTDRight\")\n",
    "        \n",
    "        # find all rows\n",
    "        rows = table.find_all(\"tr\")\n",
    "\n",
    "        # loop over rows        \n",
    "        for row in rows:\n",
    "            \n",
    "            # for reach row find all cells\n",
    "            cells = row.find_all(\"td\")\n",
    "            \n",
    "            # filter TOTAL\n",
    "            headers = [\"Year\", \"Month\", \"DOMESTIC\", \"INTERNATIONAL\", \"TOTAL\"]\n",
    "            if (cells[1].text not in headers):\n",
    "        \n",
    "                # add information to dict\n",
    "                info = {\n",
    "                    \"courier\" : info[\"courier\"],\n",
    "                    \"airport\" : info[\"airport\"],\n",
    "                    \"year\" : int(cells[0].text),\n",
    "                    \"month\" : int(cells[1].text),\n",
    "                    \"flights\" : {\n",
    "                        \"domestic\" : int(cells[2].text.replace(\",\",\"\")), # remove punctuation\n",
    "                        \"international\" : int(cells[3].text.replace(\",\",\"\")) # remove punctuation\n",
    "                        }  \n",
    "                    }\n",
    "   \n",
    "                # append info dict to data list\n",
    "                data.append(info)\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    print(\"Running a simple test...\")\n",
    "    open_zip(datadir)\n",
    "    files = process_all(datadir)\n",
    "    data = []\n",
    "    # Test will loop over three data files.\n",
    "    for f in files:\n",
    "        data += process_file(f)\n",
    "        \n",
    "    assert len(data) == 399  # Total number of rows\n",
    "    for entry in data[:3]:\n",
    "        assert type(entry[\"year\"]) == int\n",
    "        assert type(entry[\"month\"]) == int\n",
    "        assert type(entry[\"flights\"][\"domestic\"]) == int\n",
    "        assert len(entry[\"airport\"]) == 3\n",
    "        assert len(entry[\"courier\"]) == 2\n",
    "    assert data[0][\"courier\"] == 'FL'\n",
    "    assert data[0][\"month\"] == 10\n",
    "    assert data[-1][\"airport\"] == \"ATL\"\n",
    "    assert data[-1][\"flights\"] == {'international': 108289, 'domestic': 701425}\n",
    "    \n",
    "    print(\"... success!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This and the following exercise are using US Patent database. The patent.data\n",
    "file is a small excerpt of much larger datafiles that are available for\n",
    "download from US Patent website. These files are pretty large ( >100 MB each).\n",
    "The original file is ~600MB large, you might not be able to open it in a text\n",
    "editor.\n",
    "\n",
    "The data itself is in XML, however there is a problem with how it's formatted.\n",
    "Please run this script and observe the error. Then find the line that is\n",
    "causing the error. You can do that by just looking at the datafile in the web\n",
    "UI, or programmatically. For quiz purposes it does not matter, but as an\n",
    "exercise we suggest that you try to do it programmatically.\n",
    "\n",
    "NOTE: You do not need to correct the error - for now, just find where the error\n",
    "is occurring.\n",
    "\"\"\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "PATENTS = 'patent.data'\n",
    "\n",
    "def get_root(fname):\n",
    "\n",
    "    tree = ET.parse(fname)\n",
    "    return tree.getroot()\n",
    "\n",
    "\n",
    "get_root(PATENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# So, the problem is that the gigantic file is actually not a valid XML, because\n",
    "# it has several root elements, and XML declarations.\n",
    "# It is, a matter of fact, a collection of a lot of concatenated XML documents.\n",
    "# So, one solution would be to split the file into separate documents,\n",
    "# so that you can process the resulting files as valid XML documents.\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "PATENTS = 'patent.data'\n",
    "\n",
    "def get_root(fname):\n",
    "    tree = ET.parse(fname)\n",
    "    return tree.getroot()\n",
    "\n",
    "\n",
    "def split_file(filename):\n",
    "    \"\"\"\n",
    "    Split the input file into separate files, each containing a single patent.\n",
    "    As a hint - each patent declaration starts with the same line that was\n",
    "    causing the error found in the previous exercises.\n",
    "    \n",
    "    The new files should be saved with filename in the following format:\n",
    "    \"{}-{}\".format(filename, n) where n is a counter, starting from 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # open input file\n",
    "    with open(PATENTS, \"r\") as f_in:\n",
    "        \n",
    "        # read xml tag\n",
    "        xml_tag = f_in.readline()\n",
    "        \n",
    "        # split lines according to xml tag\n",
    "        lines = f_in.read().split(xml_tag)\n",
    "        \n",
    "        # loop over lines\n",
    "        for n, line in enumerate(lines):\n",
    "            \n",
    "            # write lines to separate files\n",
    "            with open(\"{}-{}\".format(PATENTS, n), \"w\") as f_out:\n",
    "                f_out.writelines(xml_tag)\n",
    "                f_out.write(line.strip())\n",
    "\n",
    "def test():\n",
    "    split_file(PATENTS)\n",
    "    for n in range(4):\n",
    "        try:\n",
    "            fname = \"{}-{}\".format(PATENTS, n)\n",
    "            f = open(fname, \"r\")\n",
    "            if not f.readline().startswith(\"<?xml\"):\n",
    "                print(\"You have not split the file {} in the correct boundary!\".format(fname))\n",
    "            f.close()\n",
    "        except:\n",
    "            print(\"Could not find file {}. Check if the filename is correct!\".format(fname))\n",
    "\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
